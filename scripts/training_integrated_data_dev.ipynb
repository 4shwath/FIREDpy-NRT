{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.cuda.amp as amp\n",
    "from torchvision import transforms\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patchify import patchify\n",
    "import torchvision.models.segmentation as models\n",
    "from segmentation_models_pytorch.metrics import iou_score, accuracy\n",
    "import rioxarray\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Suppress the specific RuntimeWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in cast\")\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        smooth = 1e-5\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_coeff = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "        \n",
    "        return 1 - dice_coeff\n",
    "\n",
    "# Combined loss function\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, weight=0.5):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce = self.bce_loss(inputs, targets)\n",
    "        dice = self.dice_loss(torch.sigmoid(inputs), targets)\n",
    "        return self.weight * bce + (1 - self.weight) * dice\n",
    "\n",
    "class SegmentationGeotiffDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, train=True, train_split=0.8, patch_size=(256, 256), stride=None):\n",
    "        self.csv_file = csv_file\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.train_split = train_split\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride if stride else patch_size\n",
    "        self.read_filenames_from_csv()\n",
    "        self.split_dataset()\n",
    "\n",
    "        self.class_frequencies = {0: 0, 1: 0}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset[idx]\n",
    "\n",
    "        # Load lum_change, coh_change, dnbr, and binary_product paths from the row\n",
    "        lum_change_path = row['lum_change']\n",
    "        coh_change_path = row['coh_change']\n",
    "        dnbr_path = row['dnbr']\n",
    "        binary_product_path = row['binary_product']\n",
    "\n",
    "        # Load and process lum_change\n",
    "        lum_change = rioxarray.open_rasterio(lum_change_path).squeeze().values\n",
    "        lum_change = np.array(transforms.ToPILImage()(lum_change).resize((1024, 1024), resample=Image.LANCZOS))\n",
    "\n",
    "        # Load and process coh_change\n",
    "        coh_change = rioxarray.open_rasterio(coh_change_path).squeeze().values\n",
    "        coh_change = np.array(transforms.ToPILImage()(coh_change).resize((1024, 1024), resample=Image.LANCZOS))\n",
    "\n",
    "        # Load and process dnbr\n",
    "        dnbr = rioxarray.open_rasterio(dnbr_path).squeeze().values\n",
    "        dnbr = np.array(transforms.ToPILImage()(dnbr).resize((1024, 1024), resample=Image.LANCZOS))\n",
    "\n",
    "        # Load and process binary_product (round to 0 or 1)\n",
    "        binary_product = rioxarray.open_rasterio(binary_product_path).squeeze().values\n",
    "        binary_product = np.rint(binary_product).astype(np.uint8)\n",
    "        binary_product = np.array(transforms.ToPILImage()(binary_product).resize((1024, 1024), resample=Image.LANCZOS))\n",
    "\n",
    "        # Stack the lum_change, coh_change, and dnbr arrays\n",
    "        stacked_array = np.stack([lum_change, coh_change, dnbr], axis=-1)\n",
    "\n",
    "        # Patchify the stacked array and binary_product\n",
    "        image_patches = patchify(stacked_array, (*self.patch_size, 3), step=(*self.stride, 3))\n",
    "        mask_patches = patchify(binary_product, self.patch_size, step=self.stride)\n",
    "\n",
    "        # Reshape patches\n",
    "        image_patches = image_patches.reshape(-1, *self.patch_size, 3)\n",
    "        mask_patches = mask_patches.reshape(-1, *self.patch_size)\n",
    "\n",
    "        # Convert to tensor\n",
    "        images = [transforms.functional.to_tensor(patch.astype(np.float32)) for patch in image_patches]\n",
    "        masks = [torch.tensor(patch, dtype=torch.long) for patch in mask_patches]\n",
    "\n",
    "        return images, masks\n",
    "    \n",
    "    def read_filenames_from_csv(self):\n",
    "        # Read filenames from CSV file\n",
    "        csv_path = os.path.join(self.csv_file)\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "\n",
    "    def extract_fire_id(self, path):\n",
    "        return int(os.path.basename(path).split('_')[0])\n",
    "\n",
    "    def split_dataset(self):\n",
    "        test_fids = [7123, 7792]\n",
    "        train_files = []\n",
    "        test_files = []\n",
    "\n",
    "        for _, row in self.data.iterrows():\n",
    "            fire_id = self.extract_fire_id(row['lum_change'])\n",
    "            if fire_id in test_fids:\n",
    "                test_files.append(row)\n",
    "            else:\n",
    "                train_files.append(row)\n",
    "        \n",
    "        if self.train:\n",
    "            self.dataset = train_files\n",
    "        else:\n",
    "            self.dataset = test_files\n",
    "    \n",
    "    def get_class_frequencies(self):\n",
    "        return self.class_frequencies\n",
    "\n",
    "def compute_iou(pred, target, num_classes):\n",
    "    pred = pred.cpu().numpy()\n",
    "    target = target.cpu().numpy()\n",
    "\n",
    "    iou_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = ((pred == cls) & (target == cls)).sum().item()\n",
    "        union = ((pred == cls) | (target == cls)).sum().item()\n",
    "        \n",
    "        if union != 0:\n",
    "            iou = intersection / union\n",
    "        else:\n",
    "            iou = 0.0\n",
    "        \n",
    "        iou_per_class.append(iou)\n",
    "    \n",
    "    mean_iou = sum(iou_per_class) / num_classes\n",
    "    return mean_iou\n",
    "\n",
    "def compute_accuracy(pred, target):\n",
    "    pred = pred.cpu().numpy()\n",
    "    target = target.cpu().numpy()\n",
    "\n",
    "    correct = (pred == target).sum().item()\n",
    "    total = target.size\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Load pre-trained DeepLabV3 model\n",
    "model = models.deeplabv3_resnet50(weights=\"DEFAULT\", progress=True)\n",
    "\n",
    "# Replace the final layer with a new layer\n",
    "num_classes = 2  # Number of classes for binary classification\n",
    "model.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
    ")\n",
    "\n",
    "# Define optimizer and Dice loss criterion\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "criterion = DiceLoss()\n",
    "\n",
    "# Checkpoint loading\n",
    "checkpoint_dir = '/Bhaltos/ASHWATH/integrated_model_checkpoints_100m_v3/'\n",
    "latest_checkpoint = max(\n",
    "    [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_epoch_') and f.endswith('.pt')],\n",
    "    key=lambda f: int(f.split('_')[-1].replace('.pt', '')),\n",
    "    default=None\n",
    ")\n",
    "if latest_checkpoint:\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint['loss']\n",
    "    print(f\"Loaded checkpoint from epoch {start_epoch-1} with loss {best_loss}\")\n",
    "else:\n",
    "    start_epoch = 1\n",
    "    best_loss = float('inf')\n",
    "    print(\"No checkpoint found, starting training from scratch.\")\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 3\n",
    "accumulation_steps = 4\n",
    "num_epochs = 20\n",
    "checkpoint_freq = 1\n",
    "best_loss = float('inf')\n",
    "patience = 5\n",
    "early_stopping_counter = 0\n",
    "\n",
    "train_dataset = SegmentationGeotiffDataset(csv_file=\"/Bhaltos/ASHWATH/metadata_v2.csv\", train=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "\n",
    "test_dataset = SegmentationGeotiffDataset(csv_file=\"/Bhaltos/ASHWATH/metadata_v2.csv\", train=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device_ids = [0, 1, 2]  # IDs of all available GPUs\n",
    "else:\n",
    "    device_ids = None\n",
    "if not isinstance(model, nn.DataParallel):\n",
    "    model = nn.DataParallel(model, device_ids=device_ids)\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to enable gradient checkpointing\n",
    "def enable_gradient_checkpointing(model):\n",
    "    # Check if the model is wrapped in DataParallel\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model = model.module\n",
    "\n",
    "    # Enable gradient checkpointing for ResNet layers\n",
    "    def enable_checkpointing(layer):\n",
    "        if hasattr(layer, 'conv1'):\n",
    "            layer.use_checkpoint = True\n",
    "\n",
    "    # Access the backbone layers\n",
    "    for layer in model.backbone.named_children():\n",
    "        if 'layer' in layer[0]:  # layer1, layer2, layer3, layer4\n",
    "            layer[1].apply(enable_checkpointing)\n",
    "\n",
    "# After model initialization and before training loop\n",
    "enable_gradient_checkpointing(model)\n",
    "\n",
    "# Create GradScaler for mixed precision training\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "# DataFrame to store metrics\n",
    "columns = ['Epoch', 'Train Loss', 'Test Loss', 'Test IoU', 'Test Accuracy']\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, num_epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (images, masks) in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch}/{num_epochs} - Training\")):\n",
    "        \n",
    "        batch_loss = 0\n",
    "        for img_patches, mask_patches in zip(images, masks):\n",
    "            image_loss = 0\n",
    "            for img, mask in zip(img_patches, mask_patches):\n",
    "                img = img.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "                mask = mask.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "                with amp.autocast():\n",
    "                    output = model(img)['out']\n",
    "                    output_probs = nn.Softmax(dim=1)(output)\n",
    "                    patch_loss = criterion(output_probs[:, 1], mask.float())\n",
    "\n",
    "                image_loss += patch_loss\n",
    "\n",
    "                # Clear unnecessary memory\n",
    "                del img, mask, output, output_probs\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Average loss for all patches in the image\n",
    "            image_loss /= len(img_patches)\n",
    "            batch_loss += image_loss\n",
    "        \n",
    "        # Average loss for all images in the batch\n",
    "        batch_loss /= len(images)\n",
    "        batch_loss = batch_loss / accumulation_steps\n",
    "\n",
    "        # Use scaler for mixed precision training\n",
    "        scaler.scale(batch_loss).backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_dataloader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += batch_loss.item() * accumulation_steps\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    iou_scores = []\n",
    "    accuracies = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_dataloader, desc=f\"Epoch {epoch}/{num_epochs} - Validation\"):\n",
    "            batch_loss = 0\n",
    "            batch_iou = 0\n",
    "            batch_accuracy = 0\n",
    "            \n",
    "            for img_patches, mask_patches in zip(images, masks):\n",
    "                image_predictions = []\n",
    "                image_masks = []\n",
    "                image_loss = 0\n",
    "                \n",
    "                for img, mask in zip(img_patches, mask_patches):\n",
    "                    img = img.unsqueeze(0).to(device)\n",
    "                    mask = mask.unsqueeze(0).to(device)\n",
    "                    \n",
    "                    with amp.autocast():\n",
    "                        output = model(img)['out']\n",
    "                        output_probs = nn.Softmax(dim=1)(output)\n",
    "                        patch_loss = criterion(output_probs[:, 1], mask.float())\n",
    "                    \n",
    "                    image_loss += patch_loss.item()\n",
    "                    output_pred = torch.argmax(output_probs, dim=1)\n",
    "                    \n",
    "                    image_predictions.append(output_pred.cpu())\n",
    "                    image_masks.append(mask.cpu())\n",
    "\n",
    "                    # Clear unnecessary memory\n",
    "                    del img, mask, output, output_probs\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                image_loss /= len(img_patches)\n",
    "                image_pred = torch.cat(image_predictions, dim=0)\n",
    "                image_mask = torch.cat(image_masks, dim=0)\n",
    "                \n",
    "                # Calculate metrics for the entire image\n",
    "                image_iou = compute_iou(image_pred, image_mask, num_classes)\n",
    "                image_accuracy = compute_accuracy(image_pred, image_mask)\n",
    "                \n",
    "                batch_loss += image_loss\n",
    "                batch_iou += image_iou\n",
    "                batch_accuracy += image_accuracy\n",
    "            \n",
    "            # Average metrics for the batch\n",
    "            batch_loss /= len(images)\n",
    "            batch_iou /= len(images)\n",
    "            batch_accuracy /= len(images)\n",
    "            \n",
    "            test_loss += batch_loss\n",
    "            iou_scores.append(batch_iou)\n",
    "            accuracies.append(batch_accuracy)\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_iou = np.mean(iou_scores)\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "    # Update metrics DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "    'Epoch': [epoch],\n",
    "    'Train Loss': [avg_train_loss],\n",
    "    'Test Loss': [avg_test_loss],\n",
    "    'Test IoU': [avg_iou],\n",
    "    'Test Accuracy': [avg_accuracy]\n",
    "    })\n",
    "    metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, IoU: {avg_iou:.4f}, Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    if avg_test_loss < best_loss:\n",
    "        best_loss = avg_test_loss\n",
    "        early_stopping_counter = 0\n",
    "        \n",
    "        # Save the model checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df.to_csv('/Bhaltos/ASHWATH/integrated_100m_training_metrics_v3.csv', index=False)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aramakrishnan/miniforge3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found, starting training from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training: 100%|██████████| 56/56 [04:49<00:00,  5.17s/it]\n",
      "Epoch 1/20 - Validation: 100%|██████████| 14/14 [00:32<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Train Loss: 0.8180, Test Loss: 0.6837, IoU: 0.3147, Accuracy: 0.6075\n",
      "Checkpoint saved to /Bhaltos/ASHWATH/integrated_model_checkpoints_100m_v7/checkpoint_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Training: 100%|██████████| 56/56 [04:44<00:00,  5.08s/it]\n",
      "Epoch 2/20 - Validation: 100%|██████████| 14/14 [00:32<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Train Loss: 0.8255, Test Loss: 0.6870, IoU: 0.3140, Accuracy: 0.6214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Training: 100%|██████████| 56/56 [04:42<00:00,  5.04s/it]\n",
      "Epoch 3/20 - Validation: 100%|██████████| 14/14 [00:31<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Train Loss: 0.8183, Test Loss: 0.6836, IoU: 0.3162, Accuracy: 0.6196\n",
      "Checkpoint saved to /Bhaltos/ASHWATH/integrated_model_checkpoints_100m_v7/checkpoint_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Training: 100%|██████████| 56/56 [04:49<00:00,  5.18s/it]\n",
      "Epoch 4/20 - Validation: 100%|██████████| 14/14 [00:31<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Train Loss: 0.8179, Test Loss: 0.6854, IoU: 0.3163, Accuracy: 0.6091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Training: 100%|██████████| 56/56 [04:44<00:00,  5.08s/it]\n",
      "Epoch 5/20 - Validation: 100%|██████████| 14/14 [00:32<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Train Loss: 0.8183, Test Loss: 0.6847, IoU: 0.3165, Accuracy: 0.6099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Training: 100%|██████████| 56/56 [04:42<00:00,  5.04s/it]\n",
      "Epoch 6/20 - Validation: 100%|██████████| 14/14 [00:32<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Train Loss: 0.8180, Test Loss: 0.6888, IoU: 0.3109, Accuracy: 0.5989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Training:  34%|███▍      | 19/56 [01:38<03:11,  5.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 416\u001b[0m\n\u001b[1;32m    413\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m--> 416\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    417\u001b[0m     output_logits \u001b[38;5;241m=\u001b[39m output[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Use logits directly\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     patch_loss \u001b[38;5;241m=\u001b[39m criterion(output_logits, mask\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:184\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:189\u001b[0m, in \u001b[0;36mDataParallel.replicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplicate\u001b[39m(\u001b[38;5;28mself\u001b[39m, module: T, device_ids: Sequence[Union[\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[T]:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/parallel/replicate.py:134\u001b[0m, in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m    132\u001b[0m module_indices[module] \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_replicas):\n\u001b[0;32m--> 134\u001b[0m     replica \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replicate_for_data_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# This is a temporary fix for DDP. DDP needs to access the\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# replicated model parameters. It used to do so through\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# `mode.parameters()`. The fix added in #33907 for DP stops the\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# `parameters()` API from exposing the replicated parameters.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Hence, we add a `_former_parameters` dict here to support DDP.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     replica\u001b[38;5;241m.\u001b[39m_former_parameters \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:2525\u001b[0m, in \u001b[0;36mModule._replicate_for_data_parallel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2521\u001b[0m replica\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;66;03m# replicas do not have parameters themselves, the replicas reference the original\u001b[39;00m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m-> 2525\u001b[0m \u001b[43mreplica\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameters\u001b[49m \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   2526\u001b[0m replica\u001b[38;5;241m.\u001b[39m_buffers \u001b[38;5;241m=\u001b[39m replica\u001b[38;5;241m.\u001b[39m_buffers\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   2527\u001b[0m replica\u001b[38;5;241m.\u001b[39m_modules \u001b[38;5;241m=\u001b[39m replica\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1700\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1697\u001b[0m                 d\u001b[38;5;241m.\u001b[39mdiscard(name)\n\u001b[1;32m   1699\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mParameter\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1702\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1703\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assign parameters before Module.__init__() call\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/parameter.py:10\u001b[0m, in \u001b[0;36m_ParameterMeta.__instancecheck__\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mself\u001b[39m, instance):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__instancecheck__\u001b[39m(instance) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(instance, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_param\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.cuda.amp as amp\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patchify import patchify\n",
    "import torchvision.models.segmentation as models\n",
    "from segmentation_models_pytorch.metrics import iou_score, accuracy\n",
    "import rioxarray\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "import cv2\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "# Suppress the specific RuntimeWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in cast\")\n",
    "\n",
    "class RobustBCELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super(RobustBCELoss, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input = torch.clamp(input, self.eps, 1 - self.eps)\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')\n",
    "        return torch.mean(torch.nan_to_num(loss, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "\n",
    "class ImprovedRobustBCELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super(ImprovedRobustBCELoss, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input = torch.clamp(input, self.eps, 1 - self.eps)\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(input, target, reduction='none')\n",
    "        \n",
    "        # Mask out NaN values in the target\n",
    "        valid_mask = ~torch.isnan(target)\n",
    "        loss = loss[valid_mask]\n",
    "        \n",
    "        if loss.numel() == 0:\n",
    "            return torch.tensor(0.0, device=input.device, requires_grad=True)\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=0.25):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()\n",
    "        total = inputs.sum() + targets.sum()\n",
    "        \n",
    "        if total == 0:\n",
    "            return torch.tensor(0.0).to(inputs.device)\n",
    "        \n",
    "        dice_coeff = (2. * intersection + self.smooth) / (total + self.smooth)\n",
    "        return 1 - dice_coeff\n",
    "\n",
    "# Combined Loss\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, weight=0.5, gamma=2, alpha=0.25):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.focal = FocalLoss(gamma, alpha)\n",
    "        self.dice = DiceLoss()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        focal_loss = self.focal(inputs, targets)\n",
    "        dice_loss = self.dice(inputs, targets)\n",
    "        combined_loss = self.weight * focal_loss + (1 - self.weight) * dice_loss\n",
    "        if torch.isnan(combined_loss):\n",
    "            print(f\"NaN in combined loss. Focal: {focal_loss}, Dice: {dice_loss}\")\n",
    "            return focal_loss if not torch.isnan(focal_loss) else dice_loss\n",
    "        return combined_loss\n",
    "\n",
    "class SegmentationGeotiffDataset(Dataset):\n",
    "    def __init__(self, csv_file, train=True, train_split=0.8, patch_size=(256, 256), stride=None):\n",
    "        self.csv_file = csv_file\n",
    "        self.train = train\n",
    "        self.train_split = train_split\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride if stride else patch_size\n",
    "        self.read_filenames_from_csv()\n",
    "        self.split_dataset()\n",
    "        self.class_frequencies = {0: 0, 1: 0}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset[idx]\n",
    "\n",
    "        # Load and process images (lum_change, coh_change, dnbr)\n",
    "        lum_change = self.load_and_resize(row['lum_change'])\n",
    "        coh_change = self.load_and_resize(row['coh_change'])\n",
    "        dnbr = self.load_and_resize(row['dnbr'])\n",
    "\n",
    "        # Load and process binary_product\n",
    "        binary_product = self.load_and_resize(row['binary_product'], is_mask=True)\n",
    "\n",
    "        # Stack the input images\n",
    "        stacked_array = np.stack([lum_change, coh_change, dnbr], axis=-1)\n",
    "\n",
    "        # Patchify the stacked array and binary_product\n",
    "        image_patches = patchify(stacked_array, (*self.patch_size, 3), step=(*self.stride, 3))\n",
    "        mask_patches = patchify(binary_product, self.patch_size, step=self.stride)\n",
    "\n",
    "        # Reshape patches\n",
    "        image_patches = image_patches.reshape(-1, *self.patch_size, 3)\n",
    "        mask_patches = mask_patches.reshape(-1, *self.patch_size)\n",
    "\n",
    "        # Apply transforms to each patch\n",
    "        transformed_images = []\n",
    "        transformed_masks = []\n",
    "        for img, mask in zip(image_patches, mask_patches):\n",
    "            # Apply transformations directly to numpy arrays\n",
    "            if self.train:  # Only apply augmentations during training\n",
    "                if random.random() > 0.5:\n",
    "                    img = np.flip(img, axis=1).copy()\n",
    "                    mask = np.flip(mask, axis=1).copy()\n",
    "                if random.random() > 0.5:\n",
    "                    img = np.flip(img, axis=0).copy()\n",
    "                    mask = np.flip(mask, axis=0).copy()\n",
    "                if random.random() > 0.5:\n",
    "                    k = random.choice([1, 2, 3])  # 90, 180, or 270 degrees\n",
    "                    img = np.rot90(img, k=k, axes=(0, 1)).copy()\n",
    "                    mask = np.rot90(mask, k=k, axes=(0, 1)).copy()\n",
    "\n",
    "            # Ensure the arrays are contiguous and in the correct range\n",
    "            img = np.ascontiguousarray(img)\n",
    "            mask = np.ascontiguousarray(mask)\n",
    "            \n",
    "            img = np.clip(img, 0, 1).astype(np.float32)\n",
    "            mask = mask.astype(np.uint8)\n",
    "\n",
    "            # Convert to tensor\n",
    "            img_tensor = torch.from_numpy(img.transpose(2, 0, 1))\n",
    "            mask_tensor = torch.from_numpy(mask).long()\n",
    "\n",
    "            transformed_images.append(img_tensor)\n",
    "            transformed_masks.append(mask_tensor)\n",
    "\n",
    "        return transformed_images, transformed_masks\n",
    "\n",
    "    def load_and_resize(self, path, is_mask=False):\n",
    "        data = rioxarray.open_rasterio(path).squeeze().values\n",
    "        \n",
    "        if not is_mask:\n",
    "            try:\n",
    "                data = preprocess_geospatial_data(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error preprocessing data from {path}: {str(e)}\")\n",
    "                # Return a default value or handle the error as appropriate\n",
    "                return np.zeros((1024, 1024), dtype=np.float32)\n",
    "        else:\n",
    "            data = (data > 0).astype(np.uint8)\n",
    "        \n",
    "        resized_image = cv2.resize(data, (1024, 1024), interpolation=cv2.INTER_NEAREST if is_mask else cv2.INTER_LANCZOS4)\n",
    "        \n",
    "        if is_mask:\n",
    "            resized_image = (resized_image > 0).astype(np.uint8)\n",
    "        else:\n",
    "            resized_image = resized_image.astype(np.float32)\n",
    "                \n",
    "        return resized_image\n",
    "    \n",
    "    def read_filenames_from_csv(self):\n",
    "        # Read filenames from CSV file\n",
    "        csv_path = os.path.join(self.csv_file)\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "\n",
    "    def extract_fire_id(self, path):\n",
    "        return int(os.path.basename(path).split('_')[0])\n",
    "\n",
    "    def split_dataset(self):\n",
    "        test_fids = [7123, 7792]\n",
    "        train_files = []\n",
    "        test_files = []\n",
    "\n",
    "        for _, row in self.data.iterrows():\n",
    "            fire_id = self.extract_fire_id(row['lum_change'])\n",
    "            if fire_id in test_fids:\n",
    "                test_files.append(row)\n",
    "            else:\n",
    "                train_files.append(row)\n",
    "        \n",
    "        if self.train:\n",
    "            self.dataset = train_files\n",
    "        else:\n",
    "            self.dataset = test_files\n",
    "    \n",
    "    def get_class_frequencies(self):\n",
    "        return self.class_frequencies\n",
    "\n",
    "def preprocess_geospatial_data(data):\n",
    "    # Replace NaN with a specific value, eg - the mean of non-NaN values\n",
    "    non_nan_mean = np.nanmean(data)\n",
    "    data = np.nan_to_num(data, nan=non_nan_mean)\n",
    "    \n",
    "    # Normalize the data\n",
    "    min_val, max_val = np.percentile(data, [1, 99])\n",
    "    \n",
    "    # Check if min_val and max_val are equal\n",
    "    if np.isclose(min_val, max_val):\n",
    "        return data.astype(np.float32)\n",
    "    \n",
    "    data = np.clip(data, min_val, max_val)\n",
    "    \n",
    "    # Add a small epsilon to avoid division by zero\n",
    "    epsilon = 1e-8\n",
    "    data = (data - min_val) / (max_val - min_val + epsilon)\n",
    "    \n",
    "    return data.astype(np.float32)\n",
    "\n",
    "def compute_iou(pred, target, num_classes):\n",
    "    pred = pred.cpu().numpy()\n",
    "    target = target.cpu().numpy()\n",
    "\n",
    "    iou_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        intersection = ((pred == cls) & (target == cls)).sum().item()\n",
    "        union = ((pred == cls) | (target == cls)).sum().item()\n",
    "        \n",
    "        if union != 0:\n",
    "            iou = intersection / union\n",
    "        else:\n",
    "            iou = 0.0\n",
    "        \n",
    "        iou_per_class.append(iou)\n",
    "    \n",
    "    mean_iou = sum(iou_per_class) / num_classes\n",
    "    return mean_iou\n",
    "\n",
    "def compute_accuracy(pred, target):\n",
    "    pred = pred.cpu().numpy()\n",
    "    target = target.cpu().numpy()\n",
    "\n",
    "    correct = (pred == target).sum().item()\n",
    "    total = target.size\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Load pre-trained DeepLabV3 model\n",
    "model = models.deeplabv3_resnet50(weights=\"DEFAULT\", progress=True)\n",
    "\n",
    "# Replace the final layer with a new layer for binary classification\n",
    "num_classes = 2\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1))\n",
    ")\n",
    "\n",
    "# Modify the first convolutional layer if input channels changed\n",
    "if model.backbone.conv1.in_channels != 3:\n",
    "    model.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# Initialize only the new layers\n",
    "model.classifier.apply(init_weights)\n",
    "if model.backbone.conv1.in_channels != 3:\n",
    "    init_weights(model.backbone.conv1)\n",
    "\n",
    "# This one worked, but not with good test IoU or test accuracy\n",
    "# optimizer = optim.AdamW([\n",
    "#     {'params': model.backbone.parameters(), 'lr': 1e-5},\n",
    "#     {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
    "# ], weight_decay=0.01)\n",
    "\n",
    "\n",
    "# 1. Adjust the learning rate\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.backbone.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
    "], weight_decay=0.01)\n",
    "\n",
    "# Add a learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# Loss function\n",
    "criterion = RobustBCELoss()\n",
    "\n",
    "# Checkpoint loading\n",
    "checkpoint_dir = '/Bhaltos/ASHWATH/integrated_model_checkpoints_100m_v7/'\n",
    "latest_checkpoint = max(\n",
    "    [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_epoch_') and f.endswith('.pt')],\n",
    "    key=lambda f: int(f.split('_')[-1].replace('.pt', '')),\n",
    "    default=None\n",
    ")\n",
    "if latest_checkpoint:\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint['loss']\n",
    "    print(f\"Loaded checkpoint from epoch {start_epoch-1} with loss {best_loss}\")\n",
    "else:\n",
    "    start_epoch = 1\n",
    "    best_loss = float('inf')\n",
    "    print(\"No checkpoint found, starting training from scratch.\")\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 3\n",
    "accumulation_steps = 8\n",
    "num_epochs = 20\n",
    "checkpoint_freq = 1\n",
    "best_loss = float('inf')\n",
    "patience = 5\n",
    "early_stopping_counter = 0\n",
    "\n",
    "train_dataset = SegmentationGeotiffDataset(csv_file=\"/Bhaltos/ASHWATH/metadata_v2.csv\", train=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "\n",
    "test_dataset = SegmentationGeotiffDataset(csv_file=\"/Bhaltos/ASHWATH/metadata_v2.csv\", train=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device_ids = [0, 1, 2]  # IDs of all available GPUs\n",
    "else:\n",
    "    device_ids = None\n",
    "if not isinstance(model, nn.DataParallel):\n",
    "    model = nn.DataParallel(model, device_ids=device_ids)\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to enable gradient checkpointing\n",
    "def enable_gradient_checkpointing(model):\n",
    "    def checkpoint_sequential(module):\n",
    "        def custom_forward(*inputs):\n",
    "            for submodule in module.children():\n",
    "                inputs = submodule(*inputs)\n",
    "            return inputs\n",
    "        return lambda *x: checkpoint(custom_forward, *x)\n",
    "\n",
    "    # Apply checkpointing to ResNet layers in the backbone\n",
    "    if hasattr(model, 'backbone'):\n",
    "        for name, module in model.backbone.named_children():\n",
    "            if name.startswith('layer'):\n",
    "                setattr(model.backbone, name, checkpoint_sequential(module))\n",
    "\n",
    "    # Apply checkpointing to ASPP module\n",
    "    if hasattr(model, 'classifier') and hasattr(model.classifier, 'aspp'):\n",
    "        model.classifier.aspp = checkpoint_sequential(model.classifier.aspp)\n",
    "\n",
    "    return model\n",
    "\n",
    "# After model initialization and before training loop\n",
    "model = enable_gradient_checkpointing(model)\n",
    "\n",
    "# Create GradScaler for mixed precision training\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "# DataFrame to store metrics\n",
    "columns = ['Epoch', 'Train Loss', 'Test Loss', 'Test IoU', 'Test Accuracy']\n",
    "metrics_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, num_epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (images, masks) in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch}/{num_epochs} - Training\")):\n",
    "        \n",
    "        batch_loss = 0\n",
    "        for img_patches, mask_patches in zip(images, masks):\n",
    "            image_loss = 0\n",
    "            for img, mask in zip(img_patches, mask_patches):\n",
    "                img = img.unsqueeze(0).to(device)\n",
    "                mask = mask.unsqueeze(0).to(device)\n",
    "\n",
    "                with amp.autocast():\n",
    "                    output = model(img)['out']\n",
    "                    output_logits = output[:, 1]  # Use logits directly\n",
    "                    patch_loss = criterion(output_logits, mask.float())\n",
    "                \n",
    "                scaler.scale(patch_loss).backward()\n",
    "\n",
    "                image_loss += patch_loss\n",
    "\n",
    "                # Clear unnecessary memory\n",
    "                del img, mask, output, output_logits\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Average loss for all patches in the image\n",
    "            image_loss /= len(img_patches)\n",
    "            batch_loss += image_loss\n",
    "\n",
    "            #scaler.scale(image_loss).backward()\n",
    "        \n",
    "        # Average loss for all images in the batch\n",
    "        batch_loss /= len(images)\n",
    "        batch_loss = batch_loss / accumulation_steps\n",
    "\n",
    "        # Use scaler for mixed precision training\n",
    "        #scaler.scale(batch_loss).backward()\n",
    "        #batch_loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_dataloader):\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            #optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += batch_loss.item() * accumulation_steps\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    iou_scores = []\n",
    "    accuracies = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_dataloader, desc=f\"Epoch {epoch}/{num_epochs} - Validation\"):\n",
    "            batch_loss = 0\n",
    "            batch_iou = 0\n",
    "            batch_accuracy = 0\n",
    "            \n",
    "            for img_patches, mask_patches in zip(images, masks):\n",
    "                image_predictions = []\n",
    "                image_masks = []\n",
    "                image_loss = 0\n",
    "                \n",
    "                for img, mask in zip(img_patches, mask_patches):\n",
    "                    img = img.unsqueeze(0).to(device)\n",
    "                    mask = mask.unsqueeze(0).to(device)\n",
    "                    \n",
    "                    with amp.autocast():\n",
    "                        output = model(img)['out']\n",
    "                        output_logits = output[:, 1]\n",
    "                        patch_loss = criterion(output_logits, mask.float())\n",
    "                    \n",
    "                    image_loss += patch_loss.item()\n",
    "                    output_pred = (torch.sigmoid(output_logits) > 0.5).long()\n",
    "                    \n",
    "                    image_predictions.append(output_pred.cpu())\n",
    "                    image_masks.append(mask.cpu())\n",
    "\n",
    "                    # Clear unnecessary memory\n",
    "                    del img, mask, output, output_logits\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                image_loss /= len(img_patches)\n",
    "                image_pred = torch.cat(image_predictions, dim=0)\n",
    "                image_mask = torch.cat(image_masks, dim=0)\n",
    "                \n",
    "                # Calculate metrics for the entire image\n",
    "                image_iou = compute_iou(image_pred, image_mask, num_classes)\n",
    "                image_accuracy = compute_accuracy(image_pred, image_mask)\n",
    "                \n",
    "                batch_loss += image_loss\n",
    "                batch_iou += image_iou\n",
    "                batch_accuracy += image_accuracy\n",
    "            \n",
    "            # Average metrics for the batch\n",
    "            batch_loss /= len(images)\n",
    "            batch_iou /= len(images)\n",
    "            batch_accuracy /= len(images)\n",
    "            \n",
    "            test_loss += batch_loss\n",
    "            iou_scores.append(batch_iou)\n",
    "            accuracies.append(batch_accuracy)\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    avg_iou = np.mean(iou_scores)\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "    # Update metrics DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "    'Epoch': [epoch],\n",
    "    'Train Loss': [avg_train_loss],\n",
    "    'Test Loss': [avg_test_loss],\n",
    "    'Test IoU': [avg_iou],\n",
    "    'Test Accuracy': [avg_accuracy]\n",
    "    })\n",
    "    metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, IoU: {avg_iou:.4f}, Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    if avg_test_loss < best_loss:\n",
    "        best_loss = avg_test_loss\n",
    "        early_stopping_counter = 0\n",
    "        \n",
    "        # Save the model checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df.to_csv('/Bhaltos/ASHWATH/integrated_100m_training_metrics_v7.csv', index=False)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Statistics:\n",
      "Total pixels: 174063616\n",
      "Class 0 pixels: 103274130 (59.33%)\n",
      "Class 1 pixels: 70789486 (40.67%)\n",
      "\n",
      "Test Dataset Statistics:\n",
      "Total pixels: 42991616\n",
      "Class 0 pixels: 16662413 (38.76%)\n",
      "Class 1 pixels: 26329203 (61.24%)\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_stats(dataset):\n",
    "    total_pixels = 0\n",
    "    class_pixels = {0: 0, 1: 0}\n",
    "    for _, masks in dataset:\n",
    "        for mask in masks:\n",
    "            total_pixels += mask.numel()\n",
    "            class_pixels[0] += (mask == 0).sum().item()\n",
    "            class_pixels[1] += (mask == 1).sum().item()\n",
    "    print(f\"Total pixels: {total_pixels}\")\n",
    "    print(f\"Class 0 pixels: {class_pixels[0]} ({class_pixels[0]/total_pixels:.2%})\")\n",
    "    print(f\"Class 1 pixels: {class_pixels[1]} ({class_pixels[1]/total_pixels:.2%})\")\n",
    "\n",
    "# Call this function after creating your datasets\n",
    "print(\"Train Dataset Statistics:\")\n",
    "print_dataset_stats(train_dataset)\n",
    "print(\"\\nTest Dataset Statistics:\")\n",
    "print_dataset_stats(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test IoU</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.992057</td>\n",
       "      <td>0.998107</td>\n",
       "      <td>0.498618</td>\n",
       "      <td>0.996358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.982693</td>\n",
       "      <td>0.992132</td>\n",
       "      <td>0.496132</td>\n",
       "      <td>0.985884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.976462</td>\n",
       "      <td>0.983806</td>\n",
       "      <td>0.478979</td>\n",
       "      <td>0.943626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.967252</td>\n",
       "      <td>0.993409</td>\n",
       "      <td>0.426016</td>\n",
       "      <td>0.847876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>0.996425</td>\n",
       "      <td>0.500336</td>\n",
       "      <td>0.997149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.959947</td>\n",
       "      <td>0.984929</td>\n",
       "      <td>0.508443</td>\n",
       "      <td>0.990969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Train Loss  Test Loss  Test IoU  Test Accuracy\n",
       "0      1    0.992057   0.998107  0.498618       0.996358\n",
       "1      2    0.982693   0.992132  0.496132       0.985884\n",
       "2      3    0.976462   0.983806  0.478979       0.943626\n",
       "3      4    0.967252   0.993409  0.426016       0.847876\n",
       "4      5    0.964017   0.996425  0.500336       0.997149\n",
       "5      6    0.959947   0.984929  0.508443       0.990969"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Bhaltos/ASHWATH/integrated_100m_training_metrics.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test IoU</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993277</td>\n",
       "      <td>0.995113</td>\n",
       "      <td>0.010434</td>\n",
       "      <td>0.023463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.988467</td>\n",
       "      <td>0.992578</td>\n",
       "      <td>0.406270</td>\n",
       "      <td>0.813274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.985425</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>0.498539</td>\n",
       "      <td>0.997085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.984510</td>\n",
       "      <td>0.987235</td>\n",
       "      <td>0.492394</td>\n",
       "      <td>0.984871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.975766</td>\n",
       "      <td>0.985969</td>\n",
       "      <td>0.492613</td>\n",
       "      <td>0.985247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.968253</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.498690</td>\n",
       "      <td>0.997381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.963056</td>\n",
       "      <td>0.977673</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.990415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.959055</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>0.498688</td>\n",
       "      <td>0.997376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.958593</td>\n",
       "      <td>0.978879</td>\n",
       "      <td>0.497337</td>\n",
       "      <td>0.994687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.955447</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.498692</td>\n",
       "      <td>0.997385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Train Loss  Test Loss  Test IoU  Test Accuracy\n",
       "0      1    0.993277   0.995113  0.010434       0.023463\n",
       "1      2    0.988467   0.992578  0.406270       0.813274\n",
       "2      3    0.985425   0.995456  0.498539       0.997085\n",
       "3      4    0.984510   0.987235  0.492394       0.984871\n",
       "4      5    0.975766   0.985969  0.492613       0.985247\n",
       "5      6    0.968253   0.999685  0.498690       0.997381\n",
       "6      7    0.963056   0.977673  0.495169       0.990415\n",
       "7      8    0.959055   0.999595  0.498688       0.997376\n",
       "8      9    0.958593   0.978879  0.497337       0.994687\n",
       "9     10    0.955447   0.999560  0.498692       0.997385"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Bhaltos/ASHWATH/integrated_100m_training_metrics_v2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test IoU</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.887011</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.49869</td>\n",
       "      <td>0.997381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.49869</td>\n",
       "      <td>0.997381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.846561</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.49869</td>\n",
       "      <td>0.997381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.49869</td>\n",
       "      <td>0.997381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.49869</td>\n",
       "      <td>0.997381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.49869</td>\n",
       "      <td>0.997381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Train Loss  Test Loss  Test IoU  Test Accuracy\n",
       "0      1    0.887011   0.846563   0.49869       0.997381\n",
       "1      2    0.846562   0.846563   0.49869       0.997381\n",
       "2      3    0.846561   0.846563   0.49869       0.997381\n",
       "3      4    0.846562   0.846563   0.49869       0.997381\n",
       "4      5    0.846562   0.846563   0.49869       0.997381\n",
       "5      6    0.846562   0.846563   0.49869       0.997381"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Bhaltos/ASHWATH/integrated_100m_training_metrics_v3.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test IoU</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.433625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189173</td>\n",
       "      <td>0.378346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.344401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189173</td>\n",
       "      <td>0.378346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.344401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.215774</td>\n",
       "      <td>0.427972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.344401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189173</td>\n",
       "      <td>0.378346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.351361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189173</td>\n",
       "      <td>0.378346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Train Loss  Test Loss  Test IoU  Test Accuracy\n",
       "0      1    0.433625        NaN  0.189173       0.378346\n",
       "1      2    0.344401        NaN  0.189173       0.378346\n",
       "2      3    0.344401        NaN  0.215774       0.427972\n",
       "3      4    0.344401        NaN  0.189173       0.378346\n",
       "4      5    0.351361        NaN  0.189173       0.378346"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Bhaltos/ASHWATH/integrated_100m_training_metrics_v4.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test IoU</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.716864</td>\n",
       "      <td>0.691347</td>\n",
       "      <td>0.225756</td>\n",
       "      <td>0.419199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.695056</td>\n",
       "      <td>0.692915</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693113</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.692090</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.690490</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693105</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693116</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.692999</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.692795</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.691509</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.378354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Train Loss  Test Loss  Test IoU  Test Accuracy\n",
       "0      1    0.716864   0.691347  0.225756       0.419199\n",
       "1      2    0.695056   0.692915  0.189177       0.378354\n",
       "2      3    0.693147   0.693113  0.189177       0.378354\n",
       "3      4    0.693147   0.692090  0.189177       0.378354\n",
       "4      5    0.693147   0.690490  0.189177       0.378354\n",
       "5      6    0.693147   0.693105  0.189177       0.378354\n",
       "6      7    0.693147   0.693116  0.189177       0.378354\n",
       "7      8    0.693147   0.692999  0.189177       0.378354\n",
       "8      9    0.693147   0.692795  0.189177       0.378354\n",
       "9     10    0.693147   0.691509  0.189177       0.378354"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Bhaltos/ASHWATH/integrated_100m_training_metrics_v5.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
